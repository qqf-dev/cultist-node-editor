{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d9cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "简洁版字段统计工具\n",
    "支持大小写不敏感匹配，统计标准字段和额外字段\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import json5\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# 定义路径\n",
    "RECIPE_PATH = os.path.join('origin_resources', 'StreamingAssets', 'content',\n",
    "                           'core', 'recipes')\n",
    "\n",
    "# 标准字段列表（标准大小写形式）\n",
    "STANDARD_FIELDS = [\n",
    "    \"id\", \"label\", \"actionId\", \"startdescription\", \"description\",\n",
    "    \"requirements\", \"extantreqs\", \"tablereqs\", \"effects\", \"aspects\",\n",
    "    \"mutations\", \"alt\", \"linked\", \"inductions\", \"slots\", \"warmup\",\n",
    "    \"maxexecutions\", \"deckeffects\", \"internaldeck\", \"burnimage\", \"ending\",\n",
    "    \"signalEndingFlavour\", \"portaleffect\", \"haltverb\", \"deleteverb\", \"purge\",\n",
    "    \"craftable\", \"hintonly\", \"signalimportantloop\", \"xpans\", \"comments\"\n",
    "]\n",
    "\n",
    "\n",
    "class FieldFrequencyAnalyzer:\n",
    "\n",
    "    def __init__(self, folder_path: str = RECIPE_PATH):\n",
    "        self.folder_path = Path(folder_path)\n",
    "\n",
    "        # 字段名大小写映射\n",
    "        self.field_map = {field.lower(): field for field in STANDARD_FIELDS}\n",
    "\n",
    "        # 统计结果\n",
    "        self.stats = {\n",
    "            'total_recipes': 0,\n",
    "            'standard_fields': Counter(),  # 标准字段出现次数\n",
    "            'extra_fields': Counter(),  # 额外字段出现次数\n",
    "            'missing_standard': defaultdict(list),  # 缺失的标准字段\n",
    "            'field_variants': defaultdict(set),  # 字段名大小写变体\n",
    "            'recipes_with_extra': defaultdict(list)  # 包含额外字段的recipes\n",
    "        }\n",
    "\n",
    "    def run_analysis(self):\n",
    "        \"\"\"运行分析\"\"\"\n",
    "        print(\"字段频率分析工具\")\n",
    "        print(f\"路径: {self.folder_path}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        if not self.folder_path.exists():\n",
    "            print(f\"错误: 路径不存在\")\n",
    "            return\n",
    "\n",
    "        # 查找JSON文件\n",
    "        json_files = list(self.folder_path.glob(\"**/*.json\"))\n",
    "\n",
    "        if not json_files:\n",
    "            print(\"未找到JSON文件\")\n",
    "            return\n",
    "\n",
    "        print(f\"找到 {len(json_files)} 个文件\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # 分析每个文件\n",
    "        for json_file in json_files:\n",
    "            self.analyze_file(json_file)\n",
    "\n",
    "        # 输出结果\n",
    "        self.print_results()\n",
    "\n",
    "        # 生成报告\n",
    "        self.generate_reports()\n",
    "\n",
    "    def analyze_file(self, file_path: Path):\n",
    "        \"\"\"分析单个文件\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            # 解析JSON\n",
    "            try:\n",
    "                data = json5.loads(content)\n",
    "            except:\n",
    "                data = json.loads(content)\n",
    "\n",
    "            if not isinstance(data, dict) or \"recipes\" not in data:\n",
    "                return\n",
    "\n",
    "            recipes = data[\"recipes\"]\n",
    "            if not isinstance(recipes, list):\n",
    "                return\n",
    "\n",
    "            file_name = file_path.name\n",
    "\n",
    "            for recipe in recipes:\n",
    "                if not isinstance(recipe, dict):\n",
    "                    continue\n",
    "\n",
    "                self.stats['total_recipes'] += 1\n",
    "                recipe_id = recipe.get(\"id\",\n",
    "                                       f\"无ID_{self.stats['total_recipes']}\")\n",
    "\n",
    "                # 分析字段\n",
    "                self.analyze_recipe(recipe, file_name, recipe_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {file_path.name} 时出错: {e}\")\n",
    "\n",
    "    def analyze_recipe(self, recipe: dict, file_name: str, recipe_id: str):\n",
    "        \"\"\"分析单个recipe的字段\"\"\"\n",
    "        recipe_fields = set(recipe.keys())\n",
    "        matched_standard = set()\n",
    "\n",
    "        for field_name in recipe_fields:\n",
    "            field_lower = field_name.lower()\n",
    "\n",
    "            # 检查是否是标准字段\n",
    "            if field_lower in self.field_map:\n",
    "                standard_field = self.field_map[field_lower]\n",
    "                self.stats['standard_fields'][standard_field] += 1\n",
    "                matched_standard.add(standard_field)\n",
    "\n",
    "                # 记录变体\n",
    "                if field_name != standard_field:\n",
    "                    self.stats['field_variants'][standard_field].add(\n",
    "                        field_name)\n",
    "            else:\n",
    "                # 额外字段\n",
    "                self.stats['extra_fields'][field_name] += 1\n",
    "                self.stats['recipes_with_extra'][field_name].append(\n",
    "                    (file_name, recipe_id))\n",
    "\n",
    "        # 检查缺失的标准字段\n",
    "        for standard_field in STANDARD_FIELDS:\n",
    "            if standard_field not in matched_standard:\n",
    "                self.stats['missing_standard'][standard_field].append(\n",
    "                    (file_name, recipe_id))\n",
    "\n",
    "    def print_results(self):\n",
    "        \"\"\"输出结果\"\"\"\n",
    "        total = self.stats['total_recipes']\n",
    "\n",
    "        print(f\"\\n分析完成:\")\n",
    "        print(f\"  总recipes数: {total}\")\n",
    "        print(f\"  标准字段数: {len(STANDARD_FIELDS)}\")\n",
    "        print(f\"  发现额外字段数: {len(self.stats['extra_fields'])}\")\n",
    "\n",
    "        # 标准字段统计\n",
    "        print(f\"\\n标准字段出现频率:\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        for field in STANDARD_FIELDS:\n",
    "            count = self.stats['standard_fields'][field]\n",
    "            missing = len(self.stats['missing_standard'][field])\n",
    "\n",
    "            if total > 0:\n",
    "                presence_rate = count / total * 100\n",
    "                missing_rate = missing / total * 100\n",
    "                print(\n",
    "                    f\"  {field:25s}: {count:5d} 出现 ({presence_rate:6.2f}%) | {missing:5d} 缺失 ({missing_rate:6.2f}%)\"\n",
    "                )\n",
    "            else:\n",
    "                print(f\"  {field:25s}: 0 出现 (0.00%) | 0 缺失 (0.00%)\")\n",
    "\n",
    "        # 额外字段统计\n",
    "        if self.stats['extra_fields']:\n",
    "            print(f\"\\n额外字段 (前10个):\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            sorted_extra = sorted(self.stats['extra_fields'].items(),\n",
    "                                  key=lambda x: x[1],\n",
    "                                  reverse=True)[:10]\n",
    "\n",
    "            for field, count in sorted_extra:\n",
    "                if total > 0:\n",
    "                    rate = count / total * 100\n",
    "                    print(f\"  {field:30s}: {count:5d} ({rate:6.2f}%)\")\n",
    "                else:\n",
    "                    print(f\"  {field:30s}: {count:5d} (0.00%)\")\n",
    "\n",
    "        # 字段名变体\n",
    "        if any(self.stats['field_variants'].values()):\n",
    "            print(f\"\\n字段名大小写变体:\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            for standard_field, variants in sorted(\n",
    "                    self.stats['field_variants'].items()):\n",
    "                if variants:\n",
    "                    print(\n",
    "                        f\"  {standard_field:25s}: {', '.join(sorted(variants))}\"\n",
    "                    )\n",
    "\n",
    "    def generate_reports(self):\n",
    "        \"\"\"生成报告文件\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        total = self.stats['total_recipes']\n",
    "\n",
    "        # 1. 标准字段详细报告\n",
    "        self.generate_standard_report(timestamp, total)\n",
    "\n",
    "        # 2. 额外字段报告\n",
    "        if self.stats['extra_fields']:\n",
    "            self.generate_extra_report(timestamp, total)\n",
    "\n",
    "        # 3. 缺失字段报告\n",
    "        self.generate_missing_report(timestamp)\n",
    "\n",
    "        # 4. 字段变体报告\n",
    "        if any(self.stats['field_variants'].values()):\n",
    "            self.generate_variants_report(timestamp)\n",
    "\n",
    "    def generate_standard_report(self, timestamp: str, total: int):\n",
    "        \"\"\"生成标准字段报告\"\"\"\n",
    "        filename = f\"standard_fields_{timestamp}.csv\"\n",
    "\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(\n",
    "                ['字段名', '出现次数', '总recipes数', '出现率%', '缺失次数', '缺失率%'])\n",
    "\n",
    "            for field in STANDARD_FIELDS:\n",
    "                count = self.stats['standard_fields'][field]\n",
    "                missing = len(self.stats['missing_standard'][field])\n",
    "\n",
    "                if total > 0:\n",
    "                    presence_rate = count / total * 100\n",
    "                    missing_rate = missing / total * 100\n",
    "                else:\n",
    "                    presence_rate = missing_rate = 0\n",
    "\n",
    "                writer.writerow([\n",
    "                    field, count, total, f\"{presence_rate:.2f}\", missing,\n",
    "                    f\"{missing_rate:.2f}\"\n",
    "                ])\n",
    "\n",
    "        print(f\"\\n标准字段报告: {filename}\")\n",
    "\n",
    "    def generate_extra_report(self, timestamp: str, total: int):\n",
    "        \"\"\"生成额外字段报告\"\"\"\n",
    "        filename = f\"extra_fields_{timestamp}.csv\"\n",
    "\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['额外字段名', '出现次数', '总recipes数', '出现率%'])\n",
    "\n",
    "            for field, count in sorted(self.stats['extra_fields'].items(),\n",
    "                                       key=lambda x: x[1],\n",
    "                                       reverse=True):\n",
    "                if total > 0:\n",
    "                    rate = count / total * 100\n",
    "                else:\n",
    "                    rate = 0\n",
    "\n",
    "                writer.writerow([field, count, total, f\"{rate:.2f}\"])\n",
    "\n",
    "        print(f\"额外字段报告: {filename}\")\n",
    "\n",
    "    def generate_missing_report(self, timestamp: str):\n",
    "        \"\"\"生成缺失字段报告\"\"\"\n",
    "        filename = f\"missing_fields_{timestamp}.txt\"\n",
    "\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"缺失标准字段报告\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "            f.write(f\"生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"总recipes数: {self.stats['total_recipes']}\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "\n",
    "            # 按缺失数量排序\n",
    "            missing_counts = {\n",
    "                field: len(recipes)\n",
    "                for field, recipes in self.stats['missing_standard'].items()\n",
    "            }\n",
    "            sorted_fields = sorted(missing_counts.items(),\n",
    "                                   key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "\n",
    "            for field, count in sorted_fields:\n",
    "                if count > 0:\n",
    "                    f.write(f\"\\n{field} (缺失 {count} 个):\\n\")\n",
    "                    f.write(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "                    # 按文件分组显示\n",
    "                    by_file = defaultdict(list)\n",
    "                    for file_name, recipe_id in self.stats['missing_standard'][\n",
    "                            field]:\n",
    "                        by_file[file_name].append(recipe_id)\n",
    "\n",
    "                    for file_name, recipe_ids in by_file.items():\n",
    "                        f.write(f\"  {file_name}: {', '.join(recipe_ids[:5])}\")\n",
    "                        if len(recipe_ids) > 5:\n",
    "                            f.write(f\" ... 还有 {len(recipe_ids) - 5} 个\")\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "        print(f\"缺失字段报告: {filename}\")\n",
    "\n",
    "    def generate_variants_report(self, timestamp: str):\n",
    "        \"\"\"生成字段变体报告\"\"\"\n",
    "        filename = f\"field_variants_{timestamp}.txt\"\n",
    "\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"字段名大小写变体报告\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "            for standard_field, variants in sorted(\n",
    "                    self.stats['field_variants'].items()):\n",
    "                if variants:\n",
    "                    f.write(f\"\\n{standard_field}:\\n\")\n",
    "                    for variant in sorted(variants):\n",
    "                        f.write(f\"  - {variant}\\n\")\n",
    "\n",
    "        print(f\"字段变体报告: {filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c719365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字段频率分析工具\n",
      "路径: origin_resources\\StreamingAssets\\content\\core\\recipes\n",
      "============================================================\n",
      "找到 90 个文件\n",
      "------------------------------------------------------------\n",
      "\n",
      "分析完成:\n",
      "  总recipes数: 2736\n",
      "  标准字段数: 31\n",
      "  发现额外字段数: 1\n",
      "\n",
      "标准字段出现频率:\n",
      "------------------------------------------------------------\n",
      "  id                       :  2736 出现 (100.00%) |     0 缺失 (  0.00%)\n",
      "  label                    :  2629 出现 ( 96.09%) |   107 缺失 (  3.91%)\n",
      "  actionId                 :  2726 出现 ( 99.63%) |    10 缺失 (  0.37%)\n",
      "  startdescription         :  2431 出现 ( 88.85%) |   305 缺失 ( 11.15%)\n",
      "  description              :  1541 出现 ( 56.32%) |  1195 缺失 ( 43.68%)\n",
      "  requirements             :  2205 出现 ( 80.59%) |   531 缺失 ( 19.41%)\n",
      "  extantreqs               :   201 出现 (  7.35%) |  2535 缺失 ( 92.65%)\n",
      "  tablereqs                :    18 出现 (  0.66%) |  2718 缺失 ( 99.34%)\n",
      "  effects                  :  1470 出现 ( 53.73%) |  1266 缺失 ( 46.27%)\n",
      "  aspects                  :   563 出现 ( 20.58%) |  2173 缺失 ( 79.42%)\n",
      "  mutations                :   195 出现 (  7.13%) |  2541 缺失 ( 92.87%)\n",
      "  alt                      :   465 出现 ( 17.00%) |  2271 缺失 ( 83.00%)\n",
      "  linked                   :  1057 出现 ( 38.63%) |  1679 缺失 ( 61.37%)\n",
      "  inductions               :    27 出现 (  0.99%) |  2709 缺失 ( 99.01%)\n",
      "  slots                    :   316 出现 ( 11.55%) |  2420 缺失 ( 88.45%)\n",
      "  warmup                   :  1729 出现 ( 63.19%) |  1007 缺失 ( 36.81%)\n",
      "  maxexecutions            :    31 出现 (  1.13%) |  2705 缺失 ( 98.87%)\n",
      "  deckeffects              :    99 出现 (  3.62%) |  2637 缺失 ( 96.38%)\n",
      "  internaldeck             :   133 出现 (  4.86%) |  2603 缺失 ( 95.14%)\n",
      "  burnimage                :    54 出现 (  1.97%) |  2682 缺失 ( 98.03%)\n",
      "  ending                   :    69 出现 (  2.52%) |  2667 缺失 ( 97.48%)\n",
      "  signalEndingFlavour      :    49 出现 (  1.79%) |  2687 缺失 ( 98.21%)\n",
      "  portaleffect             :     6 出现 (  0.22%) |  2730 缺失 ( 99.78%)\n",
      "  haltverb                 :     6 出现 (  0.22%) |  2730 缺失 ( 99.78%)\n",
      "  deleteverb               :     3 出现 (  0.11%) |  2733 缺失 ( 99.89%)\n",
      "  purge                    :    45 出现 (  1.64%) |  2691 缺失 ( 98.36%)\n",
      "  craftable                :  1406 出现 ( 51.39%) |  1330 缺失 ( 48.61%)\n",
      "  hintonly                 :   242 出现 (  8.85%) |  2494 缺失 ( 91.15%)\n",
      "  signalimportantloop      :     1 出现 (  0.04%) |  2735 缺失 ( 99.96%)\n",
      "  xpans                    :     0 出现 (  0.00%) |  2736 缺失 (100.00%)\n",
      "  comments                 :   192 出现 (  7.02%) |  2544 缺失 ( 92.98%)\n",
      "\n",
      "额外字段 (前10个):\n",
      "------------------------------------------------------------\n",
      "  achievements                  :    25 (  0.91%)\n",
      "\n",
      "字段名大小写变体:\n",
      "------------------------------------------------------------\n",
      "  actionId                 : actionid\n",
      "\n",
      "标准字段报告: standard_fields_20260128_193812.csv\n",
      "额外字段报告: extra_fields_20260128_193812.csv\n",
      "缺失字段报告: missing_fields_20260128_193812.txt\n",
      "字段变体报告: field_variants_20260128_193812.txt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "\n",
    "    analyzer = FieldFrequencyAnalyzer(RECIPE_PATH)\n",
    "    analyzer.run_analysis()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import json5\n",
    "    except ImportError:\n",
    "        print(\"请先安装: pip install json5\")\n",
    "        exit(1)\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
